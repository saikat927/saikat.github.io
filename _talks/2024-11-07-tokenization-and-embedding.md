---
title: "Tokenization and Embeddings in Large Language Models (LLMs)"
collection: talks
type: "Invited Lecture"
permalink: /talks/2024-11-07-tokenization-and-embeddings
venue: "LLM & Agentic AI Workshop organized by IDEAS TIH, ISI Kolkata"
date: 2024-11-07
location: "Online"
---

This talk presents an overview of **tokenization strategies and embedding representations** that form the foundation of modern **Large Language Models (LLMs)**. The lecture covers classical and subword-based tokenization methods, including **word-level tokenization, byte-pair encoding (BPE), and WordPiece**, and discusses their practical implications for model efficiency and scalability.

The second part of the talk focuses on **embedding techniques**, ranging from traditional static word embeddings to **contextualized representations** employed in transformer-based architectures. Emphasis is placed on understanding how tokenization and embeddings jointly influence model performance, computational efficiency, and generalization in real-world NLP applications.

[Download Slides (PDF)](/files/tokenization-and-embeddings.pdf)

